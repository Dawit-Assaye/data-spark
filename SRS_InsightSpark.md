# Software Requirements Specification (SRS)
## InsightSpark - Autonomous Insight Agent (MVP)

**Version:** 1.0  
**Date:** [Current Date]  
**Prepared for:** Brain3.ai  
**Prepared by:** [Your Name]

---

## 1. Executive Summary

### 1.1 Purpose
InsightSpark is an AI-powered autonomous data analyst agent that automates the role of a data analyst. It enables users to upload datasets and receive instant insights through natural language queries, automated code generation, execution, and visualization.

### 1.2 Scope
This MVP focuses on:
- CSV/JSON data ingestion and profiling
- Natural language query processing
- Automated Python code generation and execution
- Self-correction mechanisms for code errors
- Automatic visualization generation
- Narrative insights generation

### 1.3 Role Selection: Data Analyst
**Why Data Analyst?**
- High-impact role with measurable value (time saved, insights generated)
- Clear automation opportunities (data profiling, analysis, visualization)
- Demonstrates advanced AI capabilities (code generation, execution)
- Differentiates from common HR/Recruiting solutions
- Showcases full-stack integration with AI orchestration

---

## 2. System Overview

### 2.1 Architecture
- **Frontend:** Streamlit (Python) - Rapid UI development, 90% focus on AI logic
- **Backend:** Python with Streamlit (integrated)
- **AI Orchestration:** LangChain (Pandas DataFrame Agent) or custom ReAct loop
- **AI Model:** Google Gemini API (free tier via Google AI Studio)
- **Execution Environment:** Local Python sandbox (pandas, matplotlib, seaborn, plotly)
- **Third-Party APIs:**
  1. **Google Gemini API** - Code generation and natural language processing
  2. **GCP Cloud Scheduler** (Always Free Tier) - Proactive data health checks and insights
- **Storage:** In-memory session only (no database)

### 2.2 Technology Stack
- **Language:** Python 3.9+
- **Web Framework:** Streamlit
- **AI Framework:** LangChain / Custom ReAct implementation
- **Data Processing:** Pandas, NumPy
- **Visualization:** Plotly, Matplotlib, Seaborn
- **Cloud Services:** Google Cloud Platform (Always Free Tier)
- **API Integration:** Google Gemini API, GCP Cloud Scheduler

---

## 3. Functional Requirements

### 3.1 Data Ingestion (FR-01, FR-02)

**FR-01: File Upload**
- User can upload a single CSV or JSON file
- Maximum file size: 20MB
- Supported formats: .csv, .json
- File validation: Format check, size validation

**FR-02: Data Profiling**
Upon successful upload, system must automatically generate and display:
- First 5 rows of the dataset
- Column names and data types
- Basic statistics (row count, column count, memory usage)
- Purpose: Enable LLM to understand schema before analysis

### 3.2 Analyst Engine (FR-03, FR-04, FR-05)

**FR-03: Natural Language Query**
- User can input questions in natural language
- Examples:
  - "Show me the sales trend over time"
  - "What is the average revenue by category?"
  - "Which product has the highest sales?"
- System processes query through Gemini API

**FR-04: Code Generation & Execution (Core Feature)**
The system must:
1. Generate Python code using Pandas to answer the query
2. Execute code against the uploaded dataframe
3. Return result (number, dataframe, or error)
4. **No hallucination:** System must execute actual code, not generate fake answers

**Implementation Details:**
- Use ReAct (Reason + Act) pattern
- Prompt engineering: "You are a Python Data Analyst. You have a dataframe named `df`. Given the user request, write python code to answer it. Output ONLY the code."
- Use `exec()` wrapper for code execution (acknowledge security risks for MVP)
- Capture stdout or return variable from executed code

**FR-05: Self-Correction (The "Wow" Factor)**
- If generated code fails (e.g., KeyError, TypeError), system must:
  1. Capture the stack trace
  2. Feed error back to LLM with context
  3. Retry code generation once automatically
  4. Display error and correction attempt to user

### 3.3 Visualization & Reporting (FR-06, FR-07)

**FR-06: Auto-Visualization**
- System automatically detects if result should be visualized
- Supported chart types (MVP):
  - Bar charts
  - Line charts
  - Pie charts
- Use Plotly for interactive charts
- Charts render inline in chat stream

**FR-07: Narrative Summary**
- LLM generates 2-sentence explanation of findings
- Example: "Sales peaked in Q3 due to a 40% spike in Activity X. This represents a 25% increase compared to the previous quarter."
- Displayed after code execution and visualization

### 3.4 Proactive Features (Bonus)

**FR-08: Follow-up Suggestions**
- After answering a query, LLM suggests 3 likely follow-up questions
- Based on data context and current analysis

**FR-09: Thinking Process Transparency**
- Display raw Python code generated by AI
- Show in expandable section ("View Code")
- Builds trust and demonstrates transparency

**FR-10: Cloud Scheduler Integration**
- GCP Cloud Scheduler triggers daily data health checks
- Checks for data quality issues (missing values, outliers)
- Sends proactive insights to user (via in-app notification)

---

## 4. Non-Functional Requirements

### 4.1 Performance
- File upload processing: < 5 seconds for 20MB file
- Query response time: < 10 seconds for code generation + execution
- UI responsiveness: Real-time updates during processing

### 4.2 Security
- File uploads stored in-memory only (session-based)
- No persistent storage of user data
- Code execution in isolated environment (local sandbox)
- Input validation for file types and sizes

### 4.3 Usability
- Intuitive UI with clear file upload section
- Chat-like interface for queries
- Visual feedback during processing
- Error messages in plain language

### 4.4 Scalability
- MVP scope: Single user, single session
- No concurrent user handling required
- In-memory processing sufficient for MVP

---

## 5. System Architecture

### 5.1 Component Diagram

```
┌─────────────────┐
│   Streamlit UI  │
│  (Frontend)     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Data Processor │
│  (Pandas)       │
└────────┬────────┘
         │
         ▼
┌─────────────────┐      ┌──────────────┐
│  AI Orchestrator │◄────►│ Gemini API   │
│  (LangChain)    │      │              │
└────────┬────────┘      └──────────────┘
         │
         ▼
┌─────────────────┐
│  Code Executor  │
│  (Sandbox)      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Visualizer     │
│  (Plotly)       │
└─────────────────┘
```

### 5.2 Data Flow

1. **Upload Phase:**
   - User uploads CSV/JSON → Streamlit receives file → Pandas loads data → Profile generated → Displayed in UI

2. **Query Phase:**
   - User enters query → Sent to Gemini API → Code generated → Executed in sandbox → Result captured → Visualized (if applicable) → Summary generated → Displayed

3. **Error Handling:**
   - Code execution fails → Error captured → Sent back to Gemini → New code generated → Retry execution

---

## 6. Third-Party API Integration

### 6.1 Google Gemini API
- **Purpose:** Natural language understanding, code generation, narrative summaries
- **Free Tier:** 15 requests/minute, 1,500 requests/day
- **Usage:**
  - Query understanding
  - Python code generation
  - Error correction
  - Narrative summary generation
  - Follow-up question suggestions

### 6.2 GCP Cloud Scheduler
- **Purpose:** Proactive data health checks
- **Free Tier:** 3 jobs/month
- **Usage:**
  - Daily scheduled task to check data quality
  - Trigger insights generation
  - Send notifications (in-app)

---

## 7. User Interface Design

### 7.1 Layout
- **Header:** InsightSpark logo and title
- **Left Sidebar:** File upload section, data profile display
- **Main Area:** Chat interface for queries, results, visualizations
- **Right Sidebar (Optional):** Follow-up suggestions, code viewer

### 7.2 Key UI Components
1. **File Upload Widget:** Drag-and-drop or browse
2. **Data Profile Card:** Shows first 5 rows, column info
3. **Chat Interface:** Input box, message history
4. **Visualization Container:** Inline chart display
5. **Code Viewer:** Expandable section showing generated code
6. **Loading States:** "Thinking..." indicators

---

## 8. Implementation Plan

### 8.1 Day 1: Foundation & Ingestion
- [x] Setup project structure
- [x] Install dependencies (Streamlit, LangChain, Gemini, Pandas)
- [x] Create file uploader UI
- [x] Implement data loading (CSV/JSON)
- [x] Build DataProfile function
- [x] Display profile in UI

### 8.2 Day 2: AI Brain (Core Logic)
- [x] Setup Gemini API integration
- [x] Implement ReAct loop or LangChain agent
- [x] Build code generation prompt
- [x] Create code execution wrapper
- [x] Implement error capture and retry logic
- [ ] Test with sample queries

### 8.3 Day 3: Polish & Enhancement
- [x] Add auto-visualization logic
- [x] Implement narrative summary generation
- [ ] Add follow-up suggestions
- [x] Create code viewer component
- [ ] Style UI (CSS/Tailwind)
- [ ] Prepare demo dataset and questions
- [ ] Test end-to-end flow

---

## 9. Testing Strategy

### 9.1 Test Cases
1. **File Upload:**
   - Valid CSV upload
   - Valid JSON upload
   - Invalid file type
   - File exceeding 20MB

2. **Query Processing:**
   - Simple aggregation queries
   - Time-series analysis
   - Category-based analysis
   - Complex multi-step queries

3. **Error Handling:**
   - Invalid column names
   - Type mismatches
   - Missing data handling
   - Self-correction verification

4. **Visualization:**
   - Bar chart generation
   - Line chart generation
   - Pie chart generation
   - Appropriate chart type selection

---

## 10. Deployment Considerations

### 10.1 Local Development
- Run via: `streamlit run app.py`
- Environment variables for API keys
- `.env` file for configuration

### 10.2 Cloud Deployment (Future)
- Streamlit Cloud (free tier)
- GCP Cloud Run (Always Free Tier)
- Environment variables via cloud secrets

---

## 11. Success Metrics

### 11.1 MVP Success Criteria
- ✅ User can upload CSV/JSON and see data profile
- ✅ User can ask natural language questions
- ✅ System generates and executes correct Python code
- ✅ System self-corrects on first error
- ✅ System generates appropriate visualizations
- ✅ System provides narrative summaries
- ⏳ All features work end-to-end in demo

### 11.2 Value Proposition
- **Time Saved:** Reduces data analysis time from hours to minutes
- **Accessibility:** Non-technical users can analyze data
- **Accuracy:** Code execution ensures factual results (no hallucinations)
- **Transparency:** Code visibility builds trust

---

## 12. Risks & Mitigations

### 12.1 Technical Risks
| Risk | Impact | Mitigation |
|------|--------|------------|
| Code execution security | High | Acknowledge in documentation, use scoped libraries only |
| Gemini API rate limits | Medium | Implement request throttling, error handling |
| Large file processing | Medium | File size limits, efficient pandas operations |
| Code generation failures | High | Self-correction mechanism, fallback prompts |

### 12.2 Scope Risks
| Risk | Impact | Mitigation |
|------|--------|------------|
| Feature creep | High | Strict MVP scope, prioritize core features |
| Time constraints | High | Use Streamlit for speed, focus on AI logic |

---

## 13. Future Enhancements (Post-MVP)

- Database integration for persistent storage
- User authentication and multi-user support
- PDF export functionality
- Additional chart types (scatter, heatmap)
- Data export capabilities
- Integration with cloud storage (GCS, S3)
- Advanced error handling and logging
- Performance optimization for large datasets

---

## 14. Approval

**Status:** Pending Review  
**Next Steps:** Submit to kidus@brain3.ai for approval before implementation

---

**Document End**

